{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from music21 import converter, note, duration\n",
    "import pandas as pd\n",
    "\n",
    "# Custom Midi note object\n",
    "from midi_note import MIDINote\n",
    "\n",
    "#utility\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "from bidict import bidict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing Simulation\n",
    "\n",
    "This notebook is a gist of the overall preprocessing step the researcher applied to the dataset.\n",
    "\n",
    "![](http://www.musicxlab.com/img/logo-fine.4b1b5226.png)\n",
    "The study used the dataset from [Music-X-Lab](http://www.musicxlab.com/) from the study [POP909: A Pop-song Dataset for Music Arrangement Generation](https://arxiv.org/abs/2008.07142).\n",
    "\n",
    "Clone the data repository at [POP909](https://github.com/music-x-lab/POP909-Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# path of the data storage\n",
    "PATH = \"POP909\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "####  Data Selection for simulation\n",
    "The researcher collected all the songs belonging to 4 musical key for the simulation from the dataset:\n",
    " - E minor\n",
    " - D minor\n",
    " - A major\n",
    " - C Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "songs_by_key = dict()\n",
    "\n",
    "songs_by_key[\"Emin\"] = ['033', '034', '056', '071', '078', '116', '130', '240', '272', '276', '283', '317', '322',\n",
    "                        '380', '457', '458', '476', '501', '520', '560', '566', '578', '625', '653', '667', '680',\n",
    "                        '693', '740', '772', '788', '854', '899']\n",
    "songs_by_key[\"Dmin\"] = ['027', '040', '073', '103', '125', '141', '151', '158', '198', '226', '284', '295', '297',\n",
    "                        '344', '378', '384', '389', '446', '451', '587', '604', '610', '627', '682', '689', '791',\n",
    "                        '842', '845', '852', '859', '894']\n",
    "songs_by_key[\"Amaj\"] = ['058', '086', '102', '155', '174', '183', '208', '231', '291', '346', '353', '362', '410',\n",
    "                        '463', '475', '478', '497', '499', '615', '641', '687', '691', '721', '728', '751', '774',\n",
    "                        '810', '867', '891']\n",
    "songs_by_key[\"Cmaj\"] = ['038', '055', '068', '079', '131', '132', '136', '171', '172', '185', '203', '211', '216',\n",
    "                        '233', '243', '278', '293', '312', '319', '320', '326', '331', '368', '386', '432', '459',\n",
    "                        '493', '496', '548', '570', '591', '603', '612', '621', '702', '710', '714', '722', '735',\n",
    "                        '761', '793', '824', '833', '873', '888', '892', '909']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Song Selection\n",
    "Set how many songs will be selected for each music key using the *sample_limit* parameter.\n",
    "\n",
    "Note: *To simulate using random sample, set* **random_selection=<span style=\"color:green\">True </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_limit = 4\n",
    "all_song_ids = []\n",
    "random_selection = True\n",
    "for key, song_ids in songs_by_key.items():\n",
    "    if random_selection:\n",
    "        all_song_ids += random.sample(song_ids, sample_limit)\n",
    "    else:\n",
    "        all_song_ids += songs_by_key[key][:sample_limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parse Raw Notes Function\n",
    "\n",
    "This function parses a midi file into a python runnable data structure, filters the melody part of the midi song, and save the properties (duration type, length, pitch) a note to create a Note Object.\n",
    "<p> Example of a Note object: { note: C#4, duration_type: whole, length: 4 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: ./Varied Rhythm/A#Maj.mid\n",
      "53\n",
      "Loading Music File: ./Varied Rhythm/A#Min.mid\n",
      "50\n",
      "Loading Music File: ./Varied Rhythm/AMaj.mid\n",
      "51\n",
      "Loading Music File: ./Varied Rhythm/AMin.mid\n",
      "53\n",
      "Loading Music File: ./Varied Rhythm/BMaj.mid\n",
      "53\n",
      "Loading Music File: ./Varied Rhythm/BMin.mid\n",
      "52\n",
      "Loading Music File: ./Varied Rhythm/C#Maj.mid\n",
      "53\n",
      "Loading Music File: ./Varied Rhythm/C#Min.mid\n",
      "51\n",
      "Loading Music File: ./Varied Rhythm/CMaj.mid\n",
      "54\n",
      "Loading Music File: ./Varied Rhythm/CMin.mid\n",
      "51\n",
      "Loading Music File: ./Varied Rhythm/D#Maj.mid\n",
      "50\n",
      "Loading Music File: ./Varied Rhythm/D#Min.mid\n",
      "54\n",
      "Loading Music File: ./Varied Rhythm/DMaj.mid\n",
      "52\n",
      "Loading Music File: ./Varied Rhythm/DMin.mid\n",
      "51\n",
      "Loading Music File: ./Varied Rhythm/EMaj.mid\n",
      "53\n",
      "Loading Music File: ./Varied Rhythm/EMin.mid\n",
      "53\n",
      "Loading Music File: ./Varied Rhythm/F#Maj.mid\n",
      "51\n",
      "Loading Music File: ./Varied Rhythm/F#Min.mid\n",
      "55\n",
      "Loading Music File: ./Varied Rhythm/FMaj.mid\n",
      "52\n",
      "Loading Music File: ./Varied Rhythm/FMin.mid\n",
      "52\n",
      "Loading Music File: ./Varied Rhythm/G#Maj.mid\n",
      "52\n",
      "Loading Music File: ./Varied Rhythm/G#Min.mid\n",
      "53\n",
      "Loading Music File: ./Varied Rhythm/GMaj.mid\n",
      "54\n",
      "Loading Music File: ./Varied Rhythm/GMin.mid\n",
      "52\n",
      "[{'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'D5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'C5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'C5', 'duration_type': 'quarter', 'length': '1.0'}, {'note': 'F5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'B-4', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'B-4', 'duration_type': '16th', 'length': '0.25'}, {'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'F5', 'duration_type': 'quarter', 'length': '1.0'}, {'note': 'G5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'F5', 'duration_type': 'quarter', 'length': '1.0'}, {'note': 'D5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'D5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'C5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'C5', 'duration_type': 'eighth', 'length': '0.75'}, {'note': 'C5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'C5', 'duration_type': 'half', 'length': '2.0'}, {'note': 'F5', 'duration_type': 'eighth', 'length': '0.75'}, {'note': 'F5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'F5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'G5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'E-5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'G5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'G5', 'duration_type': 'quarter', 'length': '1.0'}, {'note': 'D5', 'duration_type': 'quarter', 'length': '1.0'}, {'note': 'C5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'C5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'D5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'D5', 'duration_type': 'quarter', 'length': '1.0'}, {'note': 'E-5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'A5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'D5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'C5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'D5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'C5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'F5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'D5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'G5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'A5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'F5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'C5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'A5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'G5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'F5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'D5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'F5', 'duration_type': '16th', 'length': '0.25'}, {'note': 'G5', 'duration_type': 'eighth', 'length': '0.5'}, {'note': 'F5', 'duration_type': '16th', 'length': '0.25'}]\n"
     ]
    }
   ],
   "source": [
    "def parse_raw_notes(file_path):\n",
    "    print(\"Loading Music File:\", file_path)\n",
    "    raw_notes = []\n",
    "    midi_data = converter.parse(file_path)\n",
    "    for part in midi_data.parts:\n",
    "        if part.partName == 'MELODY':\n",
    "            midi_elements = part.recurse()\n",
    "            for element in midi_elements:\n",
    "                if isinstance(element, note.Note):\n",
    "                    note_duration = duration.Duration()\n",
    "                    note_duration.quarterLength = element.quarterLength\n",
    "                    raw_note = str(element.pitch)\n",
    "                    raw_notes.append(MIDINote(raw_note, str(note_duration.type), str(element.quarterLength)).as_map)\n",
    "    return raw_notes\n",
    "\n",
    "\n",
    "PATH = \"./Varied Rhythm/\"\n",
    "filenames = os.listdir(PATH)\n",
    "preset_paths = [PATH + filename for filename in filenames]\n",
    "\n",
    "parsed_midi_notes = []\n",
    "for song_path in preset_paths:\n",
    "    parsed_raw_notes = parse_raw_notes(song_path)\n",
    "    print(len(parsed_raw_notes))\n",
    "    parsed_midi_notes.append(parsed_raw_notes)\n",
    "\n",
    "print(parsed_midi_notes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This function returns a random song on a given list\n",
    "This function will be used throughout the simulation to randomly select and display a song after every preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_song(song_list):\n",
    "    rand_song_id = random.randint(0, len(song_list) - 1)\n",
    "    rand_song = song_list[rand_song_id]\n",
    "    return rand_song, rand_song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song\n",
    "Get a general view of what a parsed midi song looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  note duration_type length\n0   C5        eighth    0.5\n1   C5        eighth    0.5\n2  B-4        eighth    0.5\n3   G4          16th   0.25\n4   C5        eighth    0.5\n5  B-4        eighth    0.5\n6  E-5          16th   0.25\n7   F5          16th   0.25\n8   F5        eighth    0.5\n9   C5          16th   0.25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C5</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C5</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B-4</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>G4</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C5</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>B-4</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>E-5</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>F5</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>F5</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>C5</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(parsed_midi_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song with flats\n",
    "Randomly select song to check/show flat notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "   note duration_type length\n6   B-4        eighth    0.5\n7   B-4          16th   0.25\n23  E-5        eighth    0.5\n32  E-5        eighth    0.5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>B-4</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>B-4</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>E-5</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>E-5</td>\n      <td>eighth</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if default set id = 13, 5\n",
    "random_song, random_song_id = get_random_song(parsed_midi_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "\n",
    "flats = data_frame[data_frame[\"note\"].str.contains(\"-\")]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initial preprocessing\n",
    "The initial preprocessing includes mapping of **flat** notes to its corresponding **sharp** values\n",
    "\n",
    "Example: *E-5 (E flat, 5th Octave) is equal to D#5 (D sharp, 5th Octave)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flats_map = {\n",
    "    'D-': 'C#',\n",
    "    'E-': 'D#',\n",
    "    'G-': 'F#',\n",
    "    'A-': 'G#',\n",
    "    'B-': 'A#'\n",
    "}\n",
    "\n",
    "\n",
    "def map_flat(song):\n",
    "    for song_note in song:\n",
    "        if \"-\" in song_note[\"note\"]:\n",
    "            flat_note = song_note[\"note\"][:2]\n",
    "            song_note[\"note\"] = song_note[\"note\"].replace(flat_note,\n",
    "                                                          flats_map[flat_note])\n",
    "\n",
    "\n",
    "def initial_preprocess(songs):\n",
    "    for song in songs:\n",
    "        map_flat(song)\n",
    "    return songs\n",
    "\n",
    "\n",
    "initial_preprocessed_notes = initial_preprocess(copy.deepcopy(parsed_midi_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song to check for flats\n",
    "All flats are mapped to sharps, therefore, selecting songs that contain flat values will show empty tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(initial_preprocessed_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "# show if flats still exists\n",
    "flats = data_frame[data_frame[\"note\"].str.contains(\"-\")]\n",
    "flats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song to check for complex notes\n",
    "Some songs contain complex notes, they are notes that contain *advanced duration* (notes that are complex and tuplets with fractional durations not found on basic music notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(initial_preprocessed_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show complex notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"complex\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song to check for 32nd duration typed notes\n",
    "Some songs contain notes that have 32nd duration which is not included in our proposed output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(initial_preprocessed_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show 32nd notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"32nd\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Second Preprocessing\n",
    "The second preprocessing involves mapping the standard length for each duration type, mapping complex notes\n",
    "to its nearest non-complex note, and rounding up of all 32nd duration-typed notes to 16th ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "duration_map = {\n",
    "    'whole': 4.0,\n",
    "    'half': 2.0,\n",
    "    'quarter': 1.0,\n",
    "    'eighth': 0.5,\n",
    "    '16th': 0.25,\n",
    "}\n",
    "\n",
    "\n",
    "def map_duration(song):\n",
    "    duration_type = song[\"duration_type\"]\n",
    "    if duration_type in duration_map:\n",
    "        song[\"length\"] = duration_map[duration_type]\n",
    "        return\n",
    "    # if note is 32nd then it is transformed in to 16th\n",
    "    if duration_type == \"32nd\":\n",
    "        song[\"duration_type\"] = \"16th\"\n",
    "        song[\"length\"] = 0.25\n",
    "\n",
    "    # if a note is complex then map it to its nearest non-complex note\n",
    "    if duration_type == \"complex\":\n",
    "        length = float(song[\"length\"])\n",
    "        if length <= 0.25:\n",
    "            song[\"duration_type\"] = \"16th\"\n",
    "            song[\"length\"] = \"0.25\"\n",
    "\n",
    "        minimum_duration = \"whole\"\n",
    "        distance = float('inf')\n",
    "        for duration_type, duration_length in duration_map.items():\n",
    "            if abs(duration_length - length) < distance:\n",
    "                distance = abs(duration_length - length)\n",
    "                minimum_duration = duration_type\n",
    "        song[\"duration_type\"] = minimum_duration\n",
    "        song[\"length\"] = duration_map[minimum_duration]\n",
    "\n",
    "\n",
    "def second_preprocess(songs):\n",
    "    for song in songs:\n",
    "        for song_note in song:\n",
    "            map_duration(song_note)\n",
    "    return songs\n",
    "\n",
    "\n",
    "second_preprocess_data = second_preprocess(copy.deepcopy(initial_preprocessed_notes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check if complex notes are still present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'note': 'E5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'D5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'E5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'E5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'A5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'A5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'G5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': 'quarter', 'length': 1.0},\n {'note': 'B4', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'C#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': 'quarter', 'length': 1.0},\n {'note': 'F#5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'D5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'E5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'E5', 'duration_type': 'quarter', 'length': 1.0},\n {'note': 'D5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'D5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'B5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'E5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'B5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'A5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'E5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'D5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'G5', 'duration_type': '16th', 'length': 0.25},\n {'note': 'F#5', 'duration_type': 'quarter', 'length': 1.0},\n {'note': 'F#5', 'duration_type': 'quarter', 'length': 1.0},\n {'note': 'B5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'B5', 'duration_type': 'quarter', 'length': 1.0},\n {'note': 'A5', 'duration_type': 'eighth', 'length': 0.5},\n {'note': 'F#5', 'duration_type': '16th', 'length': 0.25}]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(second_preprocess_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show complex notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"complex\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)\n",
    "random_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check if 32nd notes are still present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(second_preprocess_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show 32nd notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"32nd\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Utility functions in checking octave frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Function that returns octave frequency in all songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'5': 923, '4': 332}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_octave_frequency(songs):\n",
    "    octave_freq = {}\n",
    "    for song in songs:\n",
    "        for song_note in song:\n",
    "            octave = song_note[\"note\"][-1]\n",
    "            if octave not in octave_freq:\n",
    "                octave_freq[octave] = 0\n",
    "            octave_freq[octave] += 1\n",
    "    return octave_freq\n",
    "\n",
    "\n",
    "octave_frequency = get_octave_frequency(second_preprocess_data)\n",
    "octave_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Function that returns octave frequency of a song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def octave_frequency_by_song(song):\n",
    "    octave_freq = {}\n",
    "    for song_note in song:\n",
    "        octave = song_note[\"note\"][-1]\n",
    "        if octave not in octave_freq:\n",
    "            octave_freq[octave] = 0\n",
    "        octave_freq[octave] += 1\n",
    "    return octave_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Function that returns octave frequency of each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song no: 0\n",
      "{'5': 51, '4': 2}\n",
      "Song no: 1\n",
      "{'5': 49, '4': 1}\n",
      "Song no: 2\n",
      "{'5': 38, '4': 13}\n",
      "Song no: 3\n",
      "{'4': 8, '5': 45}\n",
      "Song no: 4\n",
      "{'5': 51, '4': 2}\n",
      "Song no: 5\n",
      "{'5': 51, '4': 1}\n",
      "Song no: 6\n",
      "{'4': 16, '5': 37}\n",
      "Song no: 7\n",
      "{'4': 18, '5': 33}\n",
      "Song no: 8\n",
      "{'5': 32, '4': 22}\n",
      "Song no: 9\n",
      "{'4': 14, '5': 37}\n",
      "Song no: 10\n",
      "{'5': 39, '4': 11}\n",
      "Song no: 11\n",
      "{'5': 30, '4': 24}\n",
      "Song no: 12\n",
      "{'4': 26, '5': 26}\n",
      "Song no: 13\n",
      "{'4': 24, '5': 27}\n",
      "Song no: 14\n",
      "{'5': 25, '4': 28}\n",
      "Song no: 15\n",
      "{'5': 44, '4': 9}\n",
      "Song no: 16\n",
      "{'5': 34, '4': 17}\n",
      "Song no: 17\n",
      "{'4': 18, '5': 37}\n",
      "Song no: 18\n",
      "{'5': 42, '4': 10}\n",
      "Song no: 19\n",
      "{'4': 20, '5': 32}\n",
      "Song no: 20\n",
      "{'5': 48, '4': 4}\n",
      "Song no: 21\n",
      "{'4': 9, '5': 44}\n",
      "Song no: 22\n",
      "{'4': 30, '5': 24}\n",
      "Song no: 23\n",
      "{'5': 47, '4': 5}\n"
     ]
    }
   ],
   "source": [
    "def octave_frequency_by_songs(songs):\n",
    "    octave_freq_list = []\n",
    "    for song in songs:\n",
    "        octave_freq_by_song = octave_frequency_by_song(song)\n",
    "        octave_freq_list.append(octave_freq_by_song)\n",
    "    return octave_freq_list\n",
    "\n",
    "\n",
    "#individual songs\n",
    "octave_frequency_list = octave_frequency_by_songs(second_preprocess_data)\n",
    "for i, ofl in enumerate(octave_frequency_list):\n",
    "    print(f\"Song no: {i}\")\n",
    "    print(ofl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song containing notes not belonging to the dominant octaves\n",
    "Some songs contain notes not belonging to 4th and fifth octaves (outlier notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(second_preprocess_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "\n",
    "flats = data_frame[(~data_frame[\"note\"].str.contains(\"4\")) & (~data_frame[\"note\"].str.contains(\"5\"))]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Third Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### This function gets the frequency of octaves of a song and sorts them\n",
    "The sorted frequency of octaves will identify the most dominant octaves of the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def octave_preprocessing(song):\n",
    "    octave_freq = octave_frequency_by_song(song)\n",
    "\n",
    "    if len(octave_freq) >= 2 or \"4\" not in octave_freq or \"5\" not in octave_freq:\n",
    "        octave_sorted = []\n",
    "        for song_key, song_key_frequency in octave_freq.items():\n",
    "            octave_sorted.append((song_key, song_key_frequency))\n",
    "        octave_sorted.sort(key=lambda x: -x[1])\n",
    "        print(octave_sorted)\n",
    "        to_dual_octaves(song, octave_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### This function rescales octaves of notes to the dominant octaves of the song\n",
    "There are only two octaves proposed in the output class of the model. Hence, songs with\n",
    "multiple octaves should rescale their outlier octaves to the nearest dominant octaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def to_dual_octaves(song, octave_sorted):\n",
    "    lower_octave_details, higher_octave_details = sorted(octave_sorted[:2], key=lambda x: x[0])\n",
    "    for song_note in song:\n",
    "        octave = song_note[\"note\"][-1]\n",
    "        if octave < lower_octave_details[0]:\n",
    "            song_note[\"note\"] = song_note[\"note\"][:-1] + lower_octave_details[0]\n",
    "        elif octave > higher_octave_details[0]:\n",
    "            song_note[\"note\"] = song_note[\"note\"][:-1] + higher_octave_details[0]\n",
    "\n",
    "    octave_freq = octave_frequency_by_song(song)\n",
    "\n",
    "    if \"4\" not in octave_freq or \"5\" not in octave_freq:\n",
    "        rescale_octave(song, lower_octave_details, higher_octave_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### This function rescales octaves to fit the octaves in output class\n",
    "Some songs have dominant octaves from 3rd to 4th octaves or from 5th to 6th octaves. This method rescales dominant\n",
    "octaves of the song to 4th and 5th octaves to fit the proposed output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rescale_octave(song, lower_octave_details, higher_octave_details):\n",
    "    lower_octave = lower_octave_details[0]\n",
    "    higher_octave = higher_octave_details[0]\n",
    "    for midi_note in song:\n",
    "        octave = midi_note[\"note\"][-1]\n",
    "        if octave == lower_octave:\n",
    "            midi_note[\"note\"] = midi_note[\"note\"][:-1] + \"4\"\n",
    "        elif octave == higher_octave:\n",
    "            midi_note[\"note\"] = midi_note[\"note\"][:-1] + \"5\"\n",
    "    note_freq_per_note = octave_frequency_by_song(song)\n",
    "    print(note_freq_per_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('5', 51), ('4', 2)]\n",
      "[('5', 49), ('4', 1)]\n",
      "[('5', 38), ('4', 13)]\n",
      "[('5', 45), ('4', 8)]\n",
      "[('5', 51), ('4', 2)]\n",
      "[('5', 51), ('4', 1)]\n",
      "[('5', 37), ('4', 16)]\n",
      "[('5', 33), ('4', 18)]\n",
      "[('5', 32), ('4', 22)]\n",
      "[('5', 37), ('4', 14)]\n",
      "[('5', 39), ('4', 11)]\n",
      "[('5', 30), ('4', 24)]\n",
      "[('4', 26), ('5', 26)]\n",
      "[('5', 27), ('4', 24)]\n",
      "[('4', 28), ('5', 25)]\n",
      "[('5', 44), ('4', 9)]\n",
      "[('5', 34), ('4', 17)]\n",
      "[('5', 37), ('4', 18)]\n",
      "[('5', 42), ('4', 10)]\n",
      "[('5', 32), ('4', 20)]\n",
      "[('5', 48), ('4', 4)]\n",
      "[('5', 44), ('4', 9)]\n",
      "[('4', 30), ('5', 24)]\n",
      "[('5', 47), ('4', 5)]\n"
     ]
    }
   ],
   "source": [
    "# run third preprocessing\n",
    "def third_preprocessing(songs):\n",
    "    for song in songs:\n",
    "        octave_preprocessing(song)\n",
    "    return songs\n",
    "\n",
    "\n",
    "third_preprocessed_data = third_preprocessing(copy.deepcopy(second_preprocess_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song containing notes not belonging to the dominant octaves\n",
    "Randomly select a song to check the effect of third preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 23\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(third_preprocessed_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show outlier octaves notes\n",
    "flats = data_frame[(~data_frame[\"note\"].str.contains(\"4\")) & (~data_frame[\"note\"].str.contains(\"5\"))]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The result of the third preprocessing based on octave_frequency on the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'5': 923, '4': 332}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octave_frequency = get_octave_frequency(third_preprocessed_data)\n",
    "octave_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conversion to Integer\n",
    "The following preprocessing step will convert the MIDI objects to integers that can be used to train the model.\n",
    "\n",
    "There are 12 notes in total within an octave (C, C#, D, D#, E, F, F#, G, G#, A, A#, B) with 5 different duration types (whole, half, quarter, eighth, 16th). The mapping that will be used groups similar pitches within an octave together, which leads to groups of 5. In total, there are `12 notes * 5 duration types * 2 octaves = 120` note mappings.\n",
    "\n",
    "`notes_map` is a bidirectional dictionary that maps the note name to the first index of the pitch's group within an octave. \n",
    "\n",
    "`train_duration_map` is a bidirectional dictionary that maps the duration type to its corresponding integer. This is used to offset the number in `notes_map` to get the correct note pitch and duration.\n",
    "\n",
    "Currently, the baseline octave is the 4th octave. Any octave above that will offset the corresponding integer by `12 notes * 5 durations = 60` indices (e.g. C4 whole note is index 0, C5 whole note is index 60, C6 whole note is 120, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "notes_map = bidict({\n",
    "    'C': 0,\n",
    "    'C#': 5,\n",
    "    'D': 10,\n",
    "    'D#': 15,\n",
    "    'E': 20,\n",
    "    'F': 25,\n",
    "    'F#': 30,\n",
    "    'G': 35,\n",
    "    'G#': 40,\n",
    "    'A': 45,\n",
    "    'A#': 50,\n",
    "    'B': 55,\n",
    "})\n",
    "train_duration_map = bidict({\n",
    "    'whole': 0,\n",
    "    'half': 1,\n",
    "    'quarter': 2,\n",
    "    'eighth': 3,\n",
    "    '16th': 4,\n",
    "})\n",
    "\n",
    "\n",
    "def map_note_to_int(song_note):\n",
    "    pitch = song_note[\"note\"][:-1]\n",
    "    octave = int(song_note[\"note\"][-1])\n",
    "\n",
    "    return notes_map[pitch] + train_duration_map[song_note[\"duration_type\"]] + ((octave - 4) * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### To trainable data, an example:\n",
    "Given the explanation of the mapping above, the calculation of the integer representation of a note is as follows:\n",
    "```\n",
    "(note_idx * 5) + duration_idx + ((octave - 4) * 60)\n",
    "```\n",
    "The `octave - 4` portion of the equation assumes that the baseline/0th index octave is 4th octave. `note_map`'s values already consider the multiplication by 5.\n",
    "\n",
    "Let's say we wish to convert a `C#4 eighth note` to an integer. `C#4` is the **2nd** note in the notes map (index 1), and `eighth` is the **4th** note in the duration map (index 3). `C#4` is in the 4th octave, which means its index will not be offset. The final calculation will be\n",
    "```\n",
    "(1 * 5) + 3 + ((4 - 4) * 60) = 8 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_note_to_int(MIDINote(\"C#4\", \"eighth\", 0.5).as_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As another example, let us convert `F5 16th note` to an integer. `F5` is the **6th** note in the notes map (index 5), and `16th` is the **5th** type in the duration map (index 4). `F5` is in the 5th octave, which means its index will be offset by `12 notes * 5 durations = 60`. The final calculation will be\n",
    "```\n",
    "(5 * 5) + 4 + ((5-4) * 60) = 89\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "89"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_note_to_int(MIDINote(\"F5\", \"16th\", 0.25).as_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The songs, after being converted to an array of `MIDINote`s, will be converted to an array of integers using the `map_note_to_int` function explained earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Applying the integer mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {'key': 'A#maj',\n  'melody': [74,\n   73,\n   63,\n   74,\n   62,\n   88,\n   53,\n   54,\n   74,\n   87,\n   98,\n   87,\n   73,\n   74,\n   73,\n   64,\n   63,\n   63,\n   61,\n   88,\n   89,\n   88,\n   99,\n   78,\n   99,\n   97,\n   72,\n   64,\n   64,\n   73,\n   74,\n   72,\n   78,\n   74,\n   108,\n   73,\n   64,\n   73,\n   63,\n   74,\n   89,\n   73,\n   99,\n   108,\n   88,\n   64,\n   108,\n   99,\n   88,\n   74,\n   89,\n   98,\n   89]},\n 1: {'key': 'A#min',\n  'melody': [114,\n   79,\n   102,\n   92,\n   77,\n   78,\n   69,\n   89,\n   94,\n   104,\n   93,\n   89,\n   78,\n   113,\n   64,\n   114,\n   78,\n   79,\n   78,\n   104,\n   104,\n   89,\n   104,\n   63,\n   78,\n   113,\n   113,\n   88,\n   113,\n   111,\n   69,\n   89,\n   88,\n   68,\n   79,\n   87,\n   77,\n   68,\n   79,\n   103,\n   104,\n   104,\n   89,\n   87,\n   68,\n   63,\n   113,\n   113,\n   54,\n   64]},\n 2: {'key': 'Amaj',\n  'melody': [82,\n   93,\n   83,\n   59,\n   59,\n   69,\n   83,\n   59,\n   58,\n   59,\n   93,\n   94,\n   84,\n   68,\n   69,\n   82,\n   84,\n   69,\n   58,\n   69,\n   59,\n   49,\n   58,\n   57,\n   74,\n   83,\n   92,\n   104,\n   109,\n   109,\n   109,\n   92,\n   84,\n   83,\n   83,\n   108,\n   104,\n   104,\n   94,\n   93,\n   83,\n   93,\n   73,\n   84,\n   93,\n   83,\n   94,\n   102,\n   59,\n   57,\n   48]},\n 3: {'key': 'Amin',\n  'melody': [49,\n   59,\n   59,\n   64,\n   98,\n   63,\n   73,\n   89,\n   108,\n   108,\n   109,\n   63,\n   108,\n   98,\n   98,\n   98,\n   108,\n   108,\n   49,\n   49,\n   48,\n   83,\n   84,\n   98,\n   84,\n   74,\n   82,\n   59,\n   64,\n   64,\n   63,\n   49,\n   88,\n   89,\n   99,\n   98,\n   107,\n   63,\n   118,\n   63,\n   72,\n   83,\n   108,\n   74,\n   109,\n   83,\n   73,\n   64,\n   118,\n   99,\n   89,\n   83,\n   108]},\n 4: {'key': 'Bmaj',\n  'melody': [79,\n   104,\n   83,\n   104,\n   103,\n   94,\n   118,\n   114,\n   93,\n   94,\n   84,\n   84,\n   84,\n   93,\n   114,\n   118,\n   78,\n   78,\n   84,\n   84,\n   69,\n   59,\n   104,\n   94,\n   84,\n   84,\n   93,\n   57,\n   119,\n   104,\n   104,\n   118,\n   104,\n   103,\n   103,\n   114,\n   104,\n   103,\n   113,\n   67,\n   83,\n   104,\n   104,\n   104,\n   102,\n   83,\n   83,\n   102,\n   118,\n   119,\n   113,\n   82,\n   84]},\n 5: {'key': 'Bmin',\n  'melody': [84,\n   73,\n   108,\n   83,\n   93,\n   93,\n   94,\n   83,\n   94,\n   94,\n   93,\n   109,\n   94,\n   108,\n   109,\n   108,\n   98,\n   92,\n   58,\n   69,\n   92,\n   93,\n   73,\n   84,\n   82,\n   73,\n   74,\n   93,\n   94,\n   94,\n   94,\n   118,\n   83,\n   118,\n   108,\n   109,\n   108,\n   108,\n   108,\n   93,\n   93,\n   83,\n   73,\n   94,\n   94,\n   99,\n   92,\n   92,\n   118,\n   117,\n   108,\n   94]},\n 6: {'key': 'C#maj',\n  'melody': [18,\n   53,\n   43,\n   64,\n   43,\n   54,\n   68,\n   34,\n   68,\n   89,\n   89,\n   68,\n   104,\n   19,\n   88,\n   78,\n   79,\n   54,\n   63,\n   19,\n   33,\n   64,\n   93,\n   79,\n   88,\n   78,\n   63,\n   68,\n   19,\n   63,\n   64,\n   54,\n   63,\n   63,\n   53,\n   34,\n   88,\n   63,\n   63,\n   64,\n   64,\n   64,\n   28,\n   62,\n   63,\n   89,\n   64,\n   63,\n   54,\n   64,\n   63,\n   79,\n   67]},\n 7: {'key': 'C#min',\n  'melody': [49,\n   68,\n   44,\n   94,\n   93,\n   82,\n   59,\n   107,\n   68,\n   68,\n   69,\n   94,\n   92,\n   43,\n   42,\n   43,\n   34,\n   93,\n   94,\n   47,\n   79,\n   67,\n   79,\n   78,\n   84,\n   69,\n   68,\n   43,\n   69,\n   83,\n   34,\n   49,\n   43,\n   48,\n   78,\n   108,\n   103,\n   108,\n   84,\n   58,\n   18,\n   84,\n   83,\n   93,\n   78,\n   69,\n   44,\n   67,\n   68,\n   58,\n   58]},\n 8: {'key': 'Cmaj',\n  'melody': [63,\n   72,\n   73,\n   62,\n   57,\n   89,\n   84,\n   59,\n   73,\n   89,\n   84,\n   47,\n   48,\n   58,\n   64,\n   64,\n   59,\n   63,\n   73,\n   88,\n   58,\n   57,\n   49,\n   39,\n   39,\n   58,\n   59,\n   49,\n   39,\n   82,\n   89,\n   74,\n   63,\n   64,\n   64,\n   64,\n   74,\n   74,\n   109,\n   64,\n   74,\n   38,\n   39,\n   83,\n   59,\n   58,\n   59,\n   64,\n   63,\n   58,\n   59,\n   73,\n   82,\n   73]},\n 9: {'key': 'Cmin',\n  'melody': [44,\n   38,\n   28,\n   73,\n   73,\n   78,\n   64,\n   73,\n   63,\n   63,\n   64,\n   43,\n   74,\n   39,\n   53,\n   54,\n   53,\n   73,\n   63,\n   62,\n   63,\n   64,\n   88,\n   74,\n   64,\n   53,\n   54,\n   63,\n   53,\n   73,\n   78,\n   73,\n   74,\n   88,\n   39,\n   64,\n   73,\n   74,\n   74,\n   63,\n   79,\n   53,\n   73,\n   89,\n   72,\n   73,\n   64,\n   53,\n   74,\n   63,\n   78]},\n 10: {'key': 'D#maj',\n  'melody': [63,\n   63,\n   53,\n   39,\n   63,\n   53,\n   79,\n   89,\n   88,\n   64,\n   78,\n   64,\n   88,\n   98,\n   64,\n   99,\n   99,\n   64,\n   79,\n   88,\n   98,\n   63,\n   64,\n   79,\n   63,\n   29,\n   99,\n   88,\n   99,\n   88,\n   88,\n   79,\n   73,\n   62,\n   78,\n   79,\n   53,\n   54,\n   39,\n   53,\n   74,\n   64,\n   73,\n   87,\n   72,\n   63,\n   64,\n   53,\n   54,\n   18]},\n 11: {'key': 'D#min',\n  'melody': [94,\n   94,\n   69,\n   54,\n   88,\n   88,\n   69,\n   78,\n   114,\n   102,\n   102,\n   93,\n   88,\n   113,\n   29,\n   93,\n   88,\n   54,\n   92,\n   93,\n   28,\n   28,\n   43,\n   44,\n   79,\n   53,\n   54,\n   58,\n   43,\n   43,\n   53,\n   33,\n   43,\n   53,\n   54,\n   68,\n   54,\n   78,\n   53,\n   58,\n   53,\n   18,\n   68,\n   68,\n   89,\n   69,\n   67,\n   88,\n   94,\n   53,\n   54,\n   94,\n   94,\n   94]},\n 12: {'key': 'Dmaj',\n  'melody': [39,\n   48,\n   47,\n   74,\n   38,\n   33,\n   73,\n   73,\n   73,\n   39,\n   39,\n   24,\n   24,\n   83,\n   83,\n   39,\n   38,\n   59,\n   69,\n   59,\n   73,\n   74,\n   83,\n   73,\n   58,\n   72,\n   83,\n   84,\n   83,\n   49,\n   48,\n   84,\n   84,\n   94,\n   38,\n   49,\n   58,\n   48,\n   37,\n   37,\n   82,\n   97,\n   73,\n   74,\n   59,\n   48,\n   48,\n   83,\n   83,\n   49,\n   98,\n   74]},\n 13: {'key': 'Dmin',\n  'melody': [39,\n   98,\n   54,\n   63,\n   63,\n   38,\n   73,\n   62,\n   54,\n   99,\n   38,\n   27,\n   73,\n   82,\n   73,\n   64,\n   53,\n   64,\n   64,\n   63,\n   53,\n   39,\n   64,\n   38,\n   28,\n   29,\n   63,\n   39,\n   38,\n   28,\n   47,\n   54,\n   114,\n   99,\n   89,\n   99,\n   64,\n   11,\n   14,\n   99,\n   84,\n   73,\n   63,\n   54,\n   37,\n   52,\n   88,\n   87,\n   83,\n   27,\n   38]},\n 14: {'key': 'Emaj',\n  'melody': [84,\n   33,\n   43,\n   48,\n   33,\n   57,\n   68,\n   59,\n   68,\n   34,\n   42,\n   48,\n   67,\n   83,\n   84,\n   84,\n   47,\n   34,\n   57,\n   78,\n   83,\n   68,\n   84,\n   49,\n   48,\n   68,\n   57,\n   48,\n   43,\n   48,\n   34,\n   34,\n   48,\n   48,\n   82,\n   93,\n   93,\n   94,\n   94,\n   94,\n   92,\n   103,\n   58,\n   58,\n   69,\n   93,\n   84,\n   59,\n   59,\n   58,\n   68,\n   47,\n   103]},\n 15: {'key': 'Emin',\n  'melody': [107,\n   118,\n   73,\n   74,\n   92,\n   94,\n   109,\n   84,\n   83,\n   73,\n   74,\n   83,\n   84,\n   82,\n   74,\n   58,\n   73,\n   58,\n   92,\n   73,\n   63,\n   108,\n   99,\n   74,\n   74,\n   98,\n   72,\n   84,\n   108,\n   72,\n   39,\n   49,\n   39,\n   83,\n   84,\n   38,\n   64,\n   74,\n   58,\n   39,\n   74,\n   83,\n   48,\n   74,\n   108,\n   118,\n   63,\n   63,\n   83,\n   74,\n   108,\n   83,\n   83]},\n 16: {'key': 'F#maj',\n  'melody': [93,\n   93,\n   93,\n   92,\n   103,\n   113,\n   103,\n   69,\n   53,\n   92,\n   104,\n   53,\n   59,\n   43,\n   59,\n   53,\n   43,\n   32,\n   53,\n   88,\n   33,\n   78,\n   43,\n   88,\n   69,\n   69,\n   59,\n   69,\n   79,\n   53,\n   79,\n   93,\n   78,\n   93,\n   58,\n   57,\n   93,\n   92,\n   88,\n   88,\n   67,\n   43,\n   103,\n   88,\n   53,\n   94,\n   78,\n   79,\n   68,\n   69,\n   68]},\n 17: {'key': 'F#min',\n  'melody': [49,\n   92,\n   94,\n   93,\n   69,\n   73,\n   108,\n   118,\n   69,\n   68,\n   107,\n   68,\n   67,\n   69,\n   58,\n   108,\n   73,\n   33,\n   33,\n   93,\n   68,\n   74,\n   74,\n   84,\n   69,\n   94,\n   83,\n   92,\n   49,\n   68,\n   48,\n   59,\n   59,\n   58,\n   59,\n   57,\n   43,\n   32,\n   58,\n   58,\n   59,\n   94,\n   82,\n   58,\n   68,\n   69,\n   69,\n   83,\n   73,\n   103,\n   92,\n   48,\n   92,\n   68,\n   93]},\n 18: {'key': 'Fmaj',\n  'melody': [63,\n   84,\n   88,\n   73,\n   63,\n   63,\n   63,\n   48,\n   74,\n   74,\n   73,\n   73,\n   84,\n   73,\n   88,\n   48,\n   83,\n   109,\n   99,\n   89,\n   89,\n   74,\n   114,\n   73,\n   74,\n   63,\n   39,\n   29,\n   38,\n   48,\n   39,\n   39,\n   48,\n   113,\n   49,\n   63,\n   108,\n   108,\n   73,\n   98,\n   98,\n   98,\n   98,\n   99,\n   63,\n   108,\n   99,\n   99,\n   88,\n   114,\n   114,\n   72]},\n 19: {'key': 'Fmin',\n  'melody': [39,\n   78,\n   64,\n   39,\n   38,\n   39,\n   39,\n   78,\n   63,\n   68,\n   64,\n   63,\n   63,\n   64,\n   89,\n   89,\n   43,\n   62,\n   63,\n   64,\n   88,\n   38,\n   62,\n   69,\n   63,\n   53,\n   54,\n   104,\n   62,\n   29,\n   63,\n   53,\n   43,\n   53,\n   64,\n   63,\n   64,\n   63,\n   68,\n   53,\n   88,\n   79,\n   88,\n   53,\n   43,\n   43,\n   89,\n   78,\n   64,\n   54,\n   29,\n   29]},\n 20: {'key': 'G#maj',\n  'melody': [78,\n   53,\n   63,\n   63,\n   78,\n   89,\n   102,\n   104,\n   103,\n   98,\n   99,\n   89,\n   78,\n   64,\n   63,\n   44,\n   64,\n   78,\n   88,\n   89,\n   63,\n   78,\n   64,\n   63,\n   79,\n   63,\n   89,\n   88,\n   87,\n   98,\n   89,\n   64,\n   88,\n   78,\n   63,\n   53,\n   53,\n   63,\n   89,\n   64,\n   62,\n   62,\n   88,\n   88,\n   87,\n   87,\n   62,\n   63,\n   63,\n   99,\n   104,\n   78]},\n 21: {'key': 'G#min',\n  'melody': [43,\n   78,\n   93,\n   78,\n   77,\n   102,\n   43,\n   54,\n   79,\n   78,\n   103,\n   83,\n   78,\n   78,\n   54,\n   84,\n   84,\n   69,\n   78,\n   43,\n   92,\n   93,\n   83,\n   83,\n   82,\n   82,\n   84,\n   114,\n   82,\n   83,\n   68,\n   68,\n   118,\n   114,\n   103,\n   103,\n   103,\n   104,\n   103,\n   59,\n   59,\n   92,\n   78,\n   83,\n   54,\n   53,\n   78,\n   104,\n   113,\n   103,\n   103,\n   93,\n   68]},\n 22: {'key': 'Gmaj',\n  'melody': [48,\n   47,\n   49,\n   63,\n   48,\n   59,\n   58,\n   59,\n   84,\n   63,\n   73,\n   63,\n   63,\n   39,\n   38,\n   58,\n   73,\n   59,\n   59,\n   59,\n   49,\n   39,\n   82,\n   83,\n   82,\n   39,\n   59,\n   59,\n   58,\n   48,\n   47,\n   59,\n   74,\n   74,\n   83,\n   64,\n   64,\n   64,\n   98,\n   99,\n   38,\n   37,\n   38,\n   38,\n   59,\n   64,\n   64,\n   59,\n   58,\n   48,\n   84,\n   73,\n   72,\n   84]},\n 23: {'key': 'Gmin',\n  'melody': [63,\n   78,\n   64,\n   108,\n   64,\n   78,\n   73,\n   64,\n   63,\n   64,\n   64,\n   63,\n   64,\n   64,\n   63,\n   73,\n   72,\n   73,\n   53,\n   63,\n   39,\n   64,\n   48,\n   63,\n   73,\n   78,\n   108,\n   98,\n   74,\n   78,\n   98,\n   73,\n   63,\n   53,\n   74,\n   78,\n   89,\n   73,\n   63,\n   108,\n   63,\n   98,\n   98,\n   88,\n   89,\n   73,\n   108,\n   98,\n   73,\n   63,\n   109,\n   53]}}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def song_map_to_int(song):\n",
    "    song_notes_to_int = []\n",
    "    for song_note in song:\n",
    "        song_notes_to_int.append(map_note_to_int(song_note))\n",
    "    return song_notes_to_int\n",
    "\n",
    "\n",
    "def songs_map_to_int(songs):\n",
    "    songs_in_int = []\n",
    "    for song in songs:\n",
    "        songs_in_int.append(song_map_to_int(song))\n",
    "    return songs_in_int\n",
    "\n",
    "\n",
    "songs_map_int = songs_map_to_int(third_preprocessed_data)\n",
    "presets = {}\n",
    "\n",
    "for i in range(len(songs_map_int)):\n",
    "    key = filenames[i].split('.')[0].replace(\"M\",\"m\")\n",
    "    presets[i] = {\"key\": key, \"melody\": songs_map_int[i]}\n",
    "\n",
    "with open(f'data/presets.npy', 'wb') as f:\n",
    "    np.save(f, presets)\n",
    "presets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generating the input data for the model\n",
    "This final process called **shift append** applies the *sliding window* algorithm of size `sequence_length` to generate\n",
    "the X, and Y values needed as an input for the model.\n",
    "\n",
    "As an example, a song (already mapped to int) has [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] elements.\n",
    "\n",
    "Given that we have `sequence_length=4`, the process for the shift append is of follows:\n",
    "\n",
    "**[ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]**\n",
    "<pre>\n",
    "    x            y\n",
    "[1, 2, 3, 4] --> [5]\n",
    "\n",
    "       x           y\n",
    "   [2, 3, 4, 5] --> [6]\n",
    "\n",
    "          x           y\n",
    "      [3, 4, 5, 6] --> [7]\n",
    "\n",
    "             x           y\n",
    "         [4, 5, 6, 7] --> [8]\n",
    "\n",
    "                x           y\n",
    "            [5, 6, 7, 8] --> [9]\n",
    "\n",
    "                   x            y\n",
    "               [6, 7, 8, 9] --> [10]\n",
    "</pre>\n",
    "Everytime the window of size `sequence_length` slides, the values inside the window are stored\n",
    "as a single `x` value and its corresponding `y` value is the element after the window.\n",
    "\n",
    "The aggregated `x` values and `y` values would then be:\n",
    "\n",
    "<pre>\n",
    "X = [                   Y = [\n",
    "    [1, 2, 3, 4],               5,\n",
    "    [2, 3, 4, 5],               6,\n",
    "    [3, 4, 5, 6],               7,\n",
    "    [4, 5, 6, 7],               8,\n",
    "    [5, 6, 7, 8],               9,\n",
    "    [6, 7, 8, 9]                10,\n",
    "]                           ]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "\n",
    "def shift_append(song_in_int, seq_len):\n",
    "    _X = []\n",
    "    _Y = []\n",
    "    limit = len(song_in_int) - seq_len\n",
    "    for index in range(limit):\n",
    "        _X.append(song_in_int[index:index + seq_len])\n",
    "        _Y.append(song_in_int[index + seq_len])\n",
    "\n",
    "    return _X, _Y\n",
    "\n",
    "\n",
    "def shift_append_songs(songs_in_int, seq_len):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for song_in_int in songs_in_int:\n",
    "        x, y = shift_append(song_in_int, seq_len)\n",
    "        X += x\n",
    "        Y += y\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "X_train, Y_train = shift_append_songs(songs_map_int, sequence_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Dimensions for X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(6286, 50)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dimensions for Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "with open(f'data/x_train_sample.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "with open(f'data/y_train_sample.npy', 'wb') as f:\n",
    "    np.save(f, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}