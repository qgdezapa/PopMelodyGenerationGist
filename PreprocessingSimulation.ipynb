{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from music21 import converter, note, duration\n",
    "import pandas as pd\n",
    "\n",
    "# Custom Midi note object\n",
    "from midi_note import MIDINote\n",
    "\n",
    "#utility\n",
    "import random\n",
    "import copy\n",
    "from bidict import bidict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Simulation\n",
    "\n",
    "This notebook is a gist of the overall preprocessing step the researcher applied to the dataset.\n",
    "\n",
    "![](http://www.musicxlab.com/img/logo-fine.4b1b5226.png)\n",
    "The study used the dataset from [Music-X-Lab](http://www.musicxlab.com/) from the study [POP909: A Pop-song Dataset for Music Arrangement Generation](https://arxiv.org/abs/2008.07142).\n",
    "\n",
    "Clone the data repository at [POP909](https://github.com/music-x-lab/POP909-Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# path of the data storage\n",
    "PATH = \"POP909\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "####  Data Selection for simulation\n",
    "The researcher collected all the songs belonging to 4 musical key for the simulation from the dataset:\n",
    " - E minor\n",
    " - D minor\n",
    " - A major\n",
    " - C Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "songs_by_key = dict()\n",
    "\n",
    "songs_by_key[\"Emin\"] = ['033', '034', '056', '071', '078', '116', '130', '240', '272', '276', '283', '317', '322',\n",
    "                        '380', '457', '458', '476', '501', '520', '560', '566', '578', '625', '653', '667', '680',\n",
    "                        '693', '740', '772', '788', '854', '899']\n",
    "songs_by_key[\"Dmin\"] = ['027', '040', '073', '103', '125', '141', '151', '158', '198', '226', '284', '295', '297',\n",
    "                        '344', '378', '384', '389', '446', '451', '587', '604', '610', '627', '682', '689', '791',\n",
    "                        '842', '845', '852', '859', '894']\n",
    "songs_by_key[\"Amaj\"] = ['058', '086', '102', '155', '174', '183', '208', '231', '291', '346', '353', '362', '410',\n",
    "                        '463', '475', '478', '497', '499', '615', '641', '687', '691', '721', '728', '751', '774',\n",
    "                        '810', '867', '891']\n",
    "songs_by_key[\"Cmaj\"] = ['038', '055', '068', '079', '131', '132', '136', '171', '172', '185', '203', '211', '216',\n",
    "                        '233', '243', '278', '293', '312', '319', '320', '326', '331', '368', '386', '432', '459',\n",
    "                        '493', '496', '548', '570', '591', '603', '612', '621', '702', '710', '714', '722', '735',\n",
    "                        '761', '793', '824', '833', '873', '888', '892', '909']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Song Selection\n",
    "Set how many songs will be selected for each music key using the *sample_limit* parameter.\n",
    "</br>\n",
    "Note: *To simulate using random sample, set* **random_selection=<span style=\"color:green\">True </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "sample_limit = 4\n",
    "all_song_ids = []\n",
    "random_selection = False\n",
    "for key, song_ids in songs_by_key.items():\n",
    "    if random_selection:\n",
    "        all_song_ids += random.sample(song_ids, sample_limit)\n",
    "    else:\n",
    "        all_song_ids += songs_by_key[key][:sample_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parse Raw Notes Function\n",
    "\n",
    "This function parses a midi file into a python runnable data structure, filters the melody part of the midi song, and save the properties (duration type, length, pitch) a note to create a Note Object.\n",
    "<p> Example of a Note object: { note: C#4, duration_type: whole, length: 4 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: POP909/033/033.mid\n",
      "Loading Music File: POP909/034/034.mid\n",
      "Loading Music File: POP909/056/056.mid\n",
      "Loading Music File: POP909/071/071.mid\n",
      "Loading Music File: POP909/027/027.mid\n",
      "Loading Music File: POP909/040/040.mid\n",
      "Loading Music File: POP909/073/073.mid\n",
      "Loading Music File: POP909/103/103.mid\n",
      "Loading Music File: POP909/058/058.mid\n",
      "Loading Music File: POP909/086/086.mid\n",
      "Loading Music File: POP909/102/102.mid\n",
      "Loading Music File: POP909/155/155.mid\n",
      "Loading Music File: POP909/038/038.mid\n",
      "Loading Music File: POP909/055/055.mid\n",
      "Loading Music File: POP909/068/068.mid\n",
      "Loading Music File: POP909/079/079.mid\n"
     ]
    }
   ],
   "source": [
    "def parse_raw_notes(file_path):\n",
    "    print(\"Loading Music File:\", file_path)\n",
    "    raw_notes = []\n",
    "    midi_data = converter.parse(file_path)\n",
    "    for part in midi_data.parts:\n",
    "        if part.partName == 'MELODY':\n",
    "            midi_elements = part.recurse()\n",
    "            for element in midi_elements:\n",
    "                if isinstance(element, note.Note):\n",
    "                    note_duration = duration.Duration()\n",
    "                    note_duration.quarterLength = element.quarterLength\n",
    "                    raw_note = str(element.pitch)\n",
    "                    raw_notes.append(MIDINote(raw_note, str(note_duration.type), str(element.quarterLength)).as_map)\n",
    "    return raw_notes\n",
    "\n",
    "\n",
    "parsed_midi_notes = []\n",
    "for song_id in all_song_ids:\n",
    "    song_path = f\"{PATH}/{song_id}/{song_id}.mid\"\n",
    "    parsed_raw_notes = parse_raw_notes(song_path)\n",
    "    parsed_midi_notes.append(parsed_raw_notes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This function returns a random song on a given list\n",
    "This function will be used throughout the simulation to randomly select and display a song after every preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_random_song(song_list):\n",
    "    rand_song_id = random.randint(0, len(song_list) - 1)\n",
    "    rand_song = song_list[rand_song_id]\n",
    "    return rand_song, rand_song_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song\n",
    "Get a general view of what a parsed midi song looks like."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "random_song, random_song_id = get_random_song(parsed_midi_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "data_frame.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  note duration_type length\n0  C#5       quarter    2/3\n1  C#5          32nd   1/12\n2   E5       quarter    2/3\n3   E5          32nd   1/12\n4  F#5       quarter    2/3\n5  F#5          32nd   1/12\n6   A4       quarter    2/3\n7   A4          32nd   1/12\n8  G#4       quarter    2/3\n9  G#4          32nd   1/12",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C#5</td>\n      <td>quarter</td>\n      <td>2/3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C#5</td>\n      <td>32nd</td>\n      <td>1/12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E5</td>\n      <td>quarter</td>\n      <td>2/3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E5</td>\n      <td>32nd</td>\n      <td>1/12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>F#5</td>\n      <td>quarter</td>\n      <td>2/3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F#5</td>\n      <td>32nd</td>\n      <td>1/12</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A4</td>\n      <td>quarter</td>\n      <td>2/3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A4</td>\n      <td>32nd</td>\n      <td>1/12</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>G#4</td>\n      <td>quarter</td>\n      <td>2/3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>G#4</td>\n      <td>32nd</td>\n      <td>1/12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song with flats\n",
    "Randomly select song to check/show flat notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": "    note duration_type length\n386  E-5        eighth    1/3\n387  E-5       quarter    2/3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>386</th>\n      <td>E-5</td>\n      <td>eighth</td>\n      <td>1/3</td>\n    </tr>\n    <tr>\n      <th>387</th>\n      <td>E-5</td>\n      <td>quarter</td>\n      <td>2/3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if default set id = 13, 5\n",
    "random_song, random_song_id = get_random_song(parsed_midi_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "\n",
    "flats = data_frame[data_frame[\"note\"].str.contains(\"-\")]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initial preprocessing\n",
    "The initial preprocessing includes mapping of **flat** notes to its corresponding **sharp** values\n",
    "\n",
    "Example: *E-5 (E flat, 5th Octave) is equal to D#5 (D sharp, 5th Octave)*"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "flats_map = {\n",
    "    'D-': 'C#',\n",
    "    'E-': 'D#',\n",
    "    'G-': 'F#',\n",
    "    'A-': 'G#',\n",
    "    'B-': 'A#'\n",
    "}\n",
    "\n",
    "\n",
    "def map_flat(song):\n",
    "    for song_note in song:\n",
    "        if \"-\" in song_note[\"note\"]:\n",
    "            flat_note = song_note[\"note\"][:2]\n",
    "            song_note[\"note\"] = song_note[\"note\"].replace(flat_note, flats_map[flat_note])\n",
    "\n",
    "\n",
    "def initial_preprocess(songs):\n",
    "    for song in songs:\n",
    "        map_flat(song)\n",
    "    return songs\n",
    "\n",
    "\n",
    "initial_preprocessed_notes = initial_preprocess(copy.deepcopy(parsed_midi_notes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song to check for flats\n",
    "All flats are mapped to sharps, therefore, selecting songs that contain flat values will show empty tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_song, random_song_id = get_random_song(initial_preprocessed_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "# show if flats still exists\n",
    "flats = data_frame[data_frame[\"note\"].str.contains(\"-\")]\n",
    "flats.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song to check for complex notes\n",
    "Some songs contain complex notes, they are notes that contain *advanced duration* (notes that are complex and tuplets with fractional durations not found on basic music notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(initial_preprocessed_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show complex notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"complex\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song to check for 32nd duration typed notes\n",
    "Some songs contain notes that have 32nd duration which is not included in our proposed output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_song, random_song_id = get_random_song(initial_preprocessed_notes)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show 32nd notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"32nd\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Second Preprocessing\n",
    "The second preprocessing involves mapping the standard length for each duration type, mapping complex notes\n",
    "to its nearest non-complex note, and rounding up of all 32nd duration-typed notes to 16th ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "duration_map = {\n",
    "    'whole': 4.0,\n",
    "    'half': 2.0,\n",
    "    'quarter': 1.0,\n",
    "    'eighth': 0.5,\n",
    "    '16th': 0.25,\n",
    "}\n",
    "\n",
    "\n",
    "def map_duration(song):\n",
    "    duration_type = song[\"duration_type\"]\n",
    "    if duration_type in duration_map:\n",
    "        song[\"length\"] = duration_map[duration_type]\n",
    "        return\n",
    "    # if note is 32nd then it is transformed in to 16th\n",
    "    if duration_type == \"32nd\":\n",
    "        song[\"duration_type\"] = \"16th\"\n",
    "        song[\"length\"] = 0.25\n",
    "\n",
    "    # if a note is complex then map it to its nearest non-complex note\n",
    "    if duration_type == \"complex\":\n",
    "        length = float(song[\"length\"])\n",
    "        if length <= 0.25:\n",
    "            song[\"duration_type\"] = \"16th\"\n",
    "            song[\"length\"] = \"0.25\"\n",
    "\n",
    "        minimum_duration = \"whole\"\n",
    "        distance = float('inf')\n",
    "        for duration_type, duration_length in duration_map.items():\n",
    "            if abs(duration_length - length) < distance:\n",
    "                distance = abs(duration_length - length)\n",
    "                minimum_duration = duration_type\n",
    "        song[\"duration_type\"] = minimum_duration\n",
    "        song[\"length\"] = duration_map[minimum_duration]\n",
    "\n",
    "\n",
    "def second_preprocess(songs):\n",
    "    for song in songs:\n",
    "        for song_note in song:\n",
    "            map_duration(song_note)\n",
    "    return songs\n",
    "\n",
    "\n",
    "second_preprocess_data = second_preprocess(copy.deepcopy(initial_preprocessed_notes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check for complex notes are still present"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(second_preprocess_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show complex notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"complex\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check if 32nd notes are still present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(second_preprocess_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show 32nd notes\n",
    "flats = data_frame[data_frame[\"duration_type\"] == \"32nd\"]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Utility functions in checking octave frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Function that returns octave frequency in all songs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "{'4': 2582, '5': 3585, '6': 1007, '3': 41}"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_octave_frequency(songs):\n",
    "    octave_freq = {}\n",
    "    for song in songs:\n",
    "        for song_note in song:\n",
    "            octave = song_note[\"note\"][-1]\n",
    "            if octave not in octave_freq:\n",
    "                octave_freq[octave] = 0\n",
    "            octave_freq[octave] += 1\n",
    "    return octave_freq\n",
    "\n",
    "\n",
    "octave_frequency = get_octave_frequency(second_preprocess_data)\n",
    "octave_frequency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Function that returns octave frequency of a song"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def octave_frequency_by_song(song):\n",
    "    octave_freq = {}\n",
    "    for song_note in song:\n",
    "        octave = song_note[\"note\"][-1]\n",
    "        if octave not in octave_freq:\n",
    "            octave_freq[octave] = 0\n",
    "        octave_freq[octave] += 1\n",
    "    return octave_freq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Function that returns octave frequency of each song"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song no: 0\n",
      "{'4': 223, '5': 151}\n",
      "Song no: 1\n",
      "{'5': 369, '6': 108, '4': 3}\n",
      "Song no: 2\n",
      "{'4': 302, '5': 163}\n",
      "Song no: 3\n",
      "{'4': 307, '5': 173, '6': 1}\n",
      "Song no: 4\n",
      "{'5': 153, '6': 231}\n",
      "Song no: 5\n",
      "{'5': 256, '6': 148}\n",
      "Song no: 6\n",
      "{'4': 431, '3': 32, '5': 22}\n",
      "Song no: 7\n",
      "{'5': 272, '6': 199}\n",
      "Song no: 8\n",
      "{'5': 174, '4': 207}\n",
      "Song no: 9\n",
      "{'5': 237, '4': 180}\n",
      "Song no: 10\n",
      "{'5': 328, '4': 154, '6': 15}\n",
      "Song no: 11\n",
      "{'4': 228, '5': 261}\n",
      "Song no: 12\n",
      "{'5': 370, '4': 72, '6': 12}\n",
      "Song no: 13\n",
      "{'4': 308, '3': 9, '5': 179, '6': 2}\n",
      "Song no: 14\n",
      "{'4': 164, '5': 267}\n",
      "Song no: 15\n",
      "{'5': 210, '6': 291, '4': 3}\n"
     ]
    }
   ],
   "source": [
    "def octave_frequency_by_songs(songs):\n",
    "    octave_freq_list = []\n",
    "    for song in songs:\n",
    "        octave_freq_by_song = octave_frequency_by_song(song)\n",
    "        octave_freq_list.append(octave_freq_by_song)\n",
    "    return octave_freq_list\n",
    "\n",
    "\n",
    "#individual songs\n",
    "octave_frequency_list = octave_frequency_by_songs(second_preprocess_data)\n",
    "for i, ofl in enumerate(octave_frequency_list):\n",
    "    print(f\"Song no: {i}\")\n",
    "    print(ofl)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View random song containing notes not belonging to the dominant octaves\n",
    "Some songs contain notes not belonging to 4th and fifth octaves (outlier notes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "    note duration_type  length\n28    C6          16th    0.25\n29    C6          16th    0.25\n30    C6          16th    0.25\n65    C6          16th    0.25\n66    C6          16th    0.25\n67    C6          16th    0.25\n110   E6        eighth    0.50\n112   D6          16th    0.25\n113   E6          16th    0.25\n114   E6        eighth    0.50",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28</th>\n      <td>C6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>C6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>C6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>C6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>C6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>C6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>E6</td>\n      <td>eighth</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>D6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>E6</td>\n      <td>16th</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>E6</td>\n      <td>eighth</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(second_preprocess_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "\n",
    "flats = data_frame[(~data_frame[\"note\"].str.contains(\"4\")) & (~data_frame[\"note\"].str.contains(\"5\"))]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Third Preprocessing\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This function gets the frequency of octaves of a song and sorts them\n",
    "The sorted frequency of octaves will identify the most dominant octaves of the song."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def octave_preprocessing(song):\n",
    "    octave_freq = octave_frequency_by_song(song)\n",
    "\n",
    "    if len(octave_freq) >= 2 or \"4\" not in octave_freq or \"5\" not in octave_freq:\n",
    "        octave_sorted = []\n",
    "        for song_key, song_key_frequency in octave_freq.items():\n",
    "            octave_sorted.append((song_key, song_key_frequency))\n",
    "        octave_sorted.sort(key=lambda x: -x[1])\n",
    "        print(octave_sorted)\n",
    "        to_dual_octaves(song, octave_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This function rescales octaves of notes to the dominant octaves of the song\n",
    "There are only two octaves proposed in the output class of the model. Hence, songs with\n",
    "multiple octaves should rescale their outlier octaves to the nearest dominant octaves."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "def to_dual_octaves(song, octave_sorted):\n",
    "    lower_octave_details, higher_octave_details = sorted(octave_sorted[:2], key=lambda x: x[0])\n",
    "    for song_note in song:\n",
    "        octave = song_note[\"note\"][-1]\n",
    "        if octave < lower_octave_details[0]:\n",
    "            song_note[\"note\"] = song_note[\"note\"][:-1] + lower_octave_details[0]\n",
    "        elif octave > higher_octave_details[0]:\n",
    "            song_note[\"note\"] = song_note[\"note\"][:-1] + higher_octave_details[0]\n",
    "\n",
    "    octave_freq = octave_frequency_by_song(song)\n",
    "\n",
    "    if \"4\" not in octave_freq or \"5\" not in octave_freq:\n",
    "        rescale_octave(song, lower_octave_details, higher_octave_details)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This function rescales octaves to fit the octaves in output class\n",
    "Some songs have dominant octaves from 3rd to 4th octaves or from 5th to 6th octaves. This method rescales dominant\n",
    "octaves of the song to 4th and 5th octaves to fit the proposed output classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "def rescale_octave(song, lower_octave_details, higher_octave_details):\n",
    "    lower_octave = lower_octave_details[0]\n",
    "    higher_octave = higher_octave_details[0]\n",
    "    for midi_note in song:\n",
    "        octave = midi_note[\"note\"][-1]\n",
    "        if octave == lower_octave:\n",
    "            midi_note[\"note\"] = midi_note[\"note\"][:-1] + \"4\"\n",
    "        elif octave == higher_octave:\n",
    "            midi_note[\"note\"] = midi_note[\"note\"][:-1] + \"5\"\n",
    "    note_freq_per_note = octave_frequency_by_song(song)\n",
    "    print(note_freq_per_note)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', 223), ('5', 151)]\n",
      "[('5', 369), ('6', 108), ('4', 3)]\n",
      "{'4': 372, '5': 108}\n",
      "[('4', 302), ('5', 163)]\n",
      "[('4', 307), ('5', 173), ('6', 1)]\n",
      "[('6', 231), ('5', 153)]\n",
      "{'4': 153, '5': 231}\n",
      "[('5', 256), ('6', 148)]\n",
      "{'4': 256, '5': 148}\n",
      "[('4', 431), ('3', 32), ('5', 22)]\n",
      "{'5': 453, '4': 32}\n",
      "[('5', 272), ('6', 199)]\n",
      "{'4': 272, '5': 199}\n",
      "[('4', 207), ('5', 174)]\n",
      "[('5', 237), ('4', 180)]\n",
      "[('5', 328), ('4', 154), ('6', 15)]\n",
      "[('5', 261), ('4', 228)]\n",
      "[('5', 370), ('4', 72), ('6', 12)]\n",
      "[('4', 308), ('5', 179), ('3', 9), ('6', 2)]\n",
      "[('5', 267), ('4', 164)]\n",
      "[('6', 291), ('5', 210), ('4', 3)]\n",
      "{'4': 213, '5': 291}\n"
     ]
    }
   ],
   "source": [
    "# run third preprocessing\n",
    "def third_preprocessing(songs):\n",
    "    for song in songs:\n",
    "        octave_preprocessing(song)\n",
    "    return songs\n",
    "\n",
    "\n",
    "third_preprocessed_data = third_preprocessing(copy.deepcopy(second_preprocess_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### View random song containing notes not belonging to the dominant octaves\n",
    "Randomly select a song to check the effect of third preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected song id: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [note, duration_type, length]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>note</th>\n      <th>duration_type</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_song, random_song_id = get_random_song(third_preprocessed_data)\n",
    "data_frame = pd.DataFrame(random_song)\n",
    "# show outlier octaves notes\n",
    "flats = data_frame[(~data_frame[\"note\"].str.contains(\"4\")) & (~data_frame[\"note\"].str.contains(\"5\"))]\n",
    "print(\"Randomly selected song id:\", random_song_id)\n",
    "flats.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The result of the third preprocessing based on octave_frequency on the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "{'4': 3452, '5': 3763}"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octave_frequency = get_octave_frequency(third_preprocessed_data)\n",
    "octave_frequency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTO TRAINABLE DATA\\n'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TO TRAINABLE DATA\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "notes_map = bidict({\n",
    "    'C': 0,\n",
    "    'C#': 5,\n",
    "    'D': 10,\n",
    "    'D#': 15,\n",
    "    'E': 20,\n",
    "    'F': 25,\n",
    "    'F#': 30,\n",
    "    'G': 35,\n",
    "    'G#': 40,\n",
    "    'A': 45,\n",
    "    'A#': 50,\n",
    "    'B': 55,\n",
    "})\n",
    "train_duration_map = bidict({\n",
    "    'whole': 0,\n",
    "    'half': 1,\n",
    "    'quarter': 2,\n",
    "    'eighth': 3,\n",
    "    '16th': 4,\n",
    "})\n",
    "\n",
    "\n",
    "def map_note_to_int(song_note):\n",
    "    pitch = song_note[\"note\"][:-1]\n",
    "    octave = int(song_note[\"note\"][-1])\n",
    "\n",
    "    return notes_map[pitch] + train_duration_map[song_note[\"duration_type\"]] + ((octave - 4) * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def song_map_to_int(song):\n",
    "    song_notes_to_int = []\n",
    "    for song_note in song:\n",
    "        song_notes_to_int.append(map_note_to_int(song_note))\n",
    "    return song_notes_to_int\n",
    "\n",
    "\n",
    "def songs_map_to_int(songs):\n",
    "    songs_in_int = []\n",
    "    for song in songs:\n",
    "        songs_in_int.append(song_map_to_int(song))\n",
    "    return songs_in_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "\n",
    "\n",
    "def shift_append(song_in_int, seq_len):\n",
    "    _X = []\n",
    "    _Y = []\n",
    "    limit = len(song_in_int) - seq_len\n",
    "    for index in range(limit):\n",
    "        _X.append(song_in_int[index:index + seq_len])\n",
    "        _Y.append(song_in_int[index + seq_len])\n",
    "\n",
    "    return _X, _Y\n",
    "\n",
    "\n",
    "def shift_append_songs(songs_in_int, seq_len):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for song_in_int in songs_in_int:\n",
    "        x, y = shift_append(song_in_int, seq_len)\n",
    "        X += x\n",
    "        Y += y\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_map_int = songs_map_to_int(third_preprocessed_data)\n",
    "len(songs_map_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = shift_append_songs(songs_map_int, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6415, 50)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6415,)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'data/x_train_sample.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "with open(f'data/y_train_sample.npy', 'wb') as f:\n",
    "    np.save(f, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}